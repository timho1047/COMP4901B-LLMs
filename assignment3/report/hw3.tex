\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{CJKutf8}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{fancyhdr}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray},
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    showstringspaces=false,
    tabsize=4
}

% Header and footer
\pagestyle{fancy}
\fancyhf{}
\lhead{COMP4901B - Large Language Models}
\rhead{Assignment 1}
\cfoot{\thepage}
\setlength{\parindent}{0pt}

% Title information
\title{
    \textbf{COMP4901B: Large Language Models} \\
    \vspace{0.5em}
    \Large Assignment 3 Report
}
\author{HE, Wenqian \\ Student ID: 20860896}
\date{\today}

\begin{document}

\maketitle


\section{Part 1 — VLLM Inference Implementation}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/part1.png}
    \caption{VLLM Inference}
    \label{fig:vllm_inference}
\end{figure}

\subsection{Implementation}

\textbf{\texttt{format\_prompts()}} I followed the all instructions to implement this function. The quesiton is formatted using specified prompt template by default, then the formatted prompt is applied chat template from tokenizer with optional system message unless exception occurs, otherwise the raw formatted prompt without chat template is used.

\textbf{\texttt{run\_inference()}} I followed the all instructions to implement this function. I pass all necessary parameters to LLM engine and sampling parameters. Specially, If the number of rollouts is greater than 1, but temperature is 0.0, the temperature is increased to 0.6 by default to avoid deterministic output. If the number of rollouts is 1, the temperature is set to 0.0 to avoid stochastic output. Otherwise the temperature is set to the specified temperature.

\subsection{Answer the question}

We need temperature > 0 when generating multiple rollouts because when temperature is 0, the model will generate the same output for each rollout, then there is no meaning to generate multiple rollouts. So we should set temperature > 0 to generate diverse outputs.


\section{Part 2 — Answer Verification Implementation}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/part2.png}
    \caption{Answer Verification}
    \label{fig:answer_verification}
\end{figure}

\subsection{Implementation}

\begin{lstlisting}[language=Python]
BOX_PATTERN = r'\\boxed\{([^}]+)\}'
NUMBER_PATTERN = r'(-?(?:\d{1,3}(?:,\d{3})*|\d+)(?:\.\d+)?)'
\end{lstlisting}

\textbf{\texttt{extract\_solution()}} I first try to extract the answer in boxed format using the pattern \texttt{BOX\_PATTERN}, then if not found, I try to extract the answer in number format using the pattern \texttt{NUMBER\_PATTERN}. The last extracted answer is returned without commas and dollar signs. If both failed, I return None. 

\textbf{\texttt{compute\_score()}} I casted the extracted answer and ground truth to float and back to string to compare the values. This operation is performed in try-except block to handle non-numeric values. If the comparison is successful, it returned the comparison result otherwise 0 is returned.

\subsection{Derivation of the pass@k metric}

\begin{align*}
    \text{pass@k} &= P(\text{at least one correct}) \\
    &= 1 - P(\text{all are wrong}) \\
    &= 1 - \frac{\binom{n-c}{k}}{\binom{n}{k}} \\
    &= 1 - \frac{(n-c)!}{k!(n-c-k)!} \times \frac{k!(n-k)!}{n!} \\
    &= 1 - \frac{(n-c-k+1)(n-c-k+2)\cdots(n-c)}{(n-k+1)(n-k+2)\cdots(n)} \\
    &= 1 - \prod_{i=1}^{k} \frac{n-c-k+i}{n-k+i}
\end{align*}

\subsection{Answer the question}

\begin{lstlisting}
ratios = np.arange(n-c-k+1, n-c+1) / np.arange(n-k+1, n+1)
pass_at_k_values[i] = 1 - np.prod(ratios)
\end{lstlisting}

The numerical stability is achieved by using the product formulation of the pass@k metric. I created a 1d array of \[n-c-k+1, n-c-k+2, \cdots, n-c\] and a 1d array of \[n-k+1, n-k+2, \cdots, n\] then divide the corresponding elements to get the 1d array of ratios. Then the pass@k is 1 minus the product of the ratios. This avoids the computation of large factorials and division of large numbers.

\section{Part 3 — LoRA Training Implementation}

\begin{lstlisting}[language=Python]
def _resolve_lora_target_modules(self) -> List[str]:
    VALID_TARGETS_BY_MODEL = {
        "qwen3": {"q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"},
        "llama": {'o_proj', 'k_proj', 'up_proj', 'gate_proj', 'v_proj', 'q_proj', 'down_proj'},
        "mistral": {'k_proj', 'o_proj', 'down_proj', 'q_proj', 'up_proj', 'gate_proj', 'v_proj'},
        "opt": {'k_proj', 'q_proj', 'fc1', 'v_proj', 'out_proj', 'fc2'}
    }
    
    model_type: str = self.model.config.model_type
                    
    if self.lora_args.lora_target_modules:
        targets = set(self.lora_args.lora_target_modules)
    elif model_type in VALID_TARGETS_BY_MODEL:
        targets = VALID_TARGETS_BY_MODEL[model_type]
    else:
        raise ValueError(f"No valid target modules found for model type: {model_type}")
        
    available_modules = {name.split(".")[-1] for name, module in self.model.named_modules() if isinstance(module, nn.Linear)}

    assert targets <= available_modules, f"Invalid target modules: {targets} not in {available_modules}"
    valid_targets = list(targets)
    
    return valid_targets
\end{lstlisting}

\subsection{Detect architecture and select target modules}

I use \texttt{self.model.config.model\_type} to detect the architecture of the model. I downloaded \texttt{Qwen/Qwen3-0.6B}, \texttt{unsloth/Llama-3.2-1B}, \texttt{unsloth/mistral-7b-bnb-4bit} and \texttt{facebook/opt-125m} models from Hugging Face, then printed the model type string, model architecture, and linear module names. Then I picked the name of linear modules in decoder layers for each model. They are the default valid target modules for forementioned models if no target modules are specified. Details can be found in the \texttt{scripts/model.ipynb} file.

\subsection{Answer the question}
In decoder-only transformer models, the attention layers are used to correlate different parts of the input sequence, i.e. attend to appropriate positions. The FFN layers are used to store the knowledge, such as math operation patterns. Finetuning lora on attention and FFN layers can help the model focus on the important numbers and quesiton intention keywords for GSM8K-like math problems, then match the learned patterns in FFN layers to perform math reasoning. 
\newline

If we only apply lora to attention layers, although it might improve the model's attention on some important number of keywords, but it cannot learn new patterns, such as for which kind of question should it apply division or multiplication. 
\newline

Moreover, since the model cannot learn new pattern, it might not be able to extract better features in lower layers through FFN, then higher attention layers cannot pay attention to good positions since they are not similar in terms of features, even though they might relevant in eyes of humans.

\section{Part 4 — Part 4 — Self-Training Execution}
\subsection{Training Configuration Summary}
\begin{lstlisting}
NUM_ITERATIONS=1
MAX_TOKENS=512
N_ROLLOUTS=8
ENABLE_THINKING=false
N_QUERIES=2000

LEARNING_RATE=2e-5
TOTAL_BATCH_SIZE=128
NUM_EPOCHS=1
SAVE_STEPS=30
LORA_R=64
\end{lstlisting}

\subsection{Metrics}

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{Iteration} & \textbf{\#Correct} & \textbf{Pass@1} & \textbf{Pass@4} & \textbf{Pass@8} \\
        \hline
        0 & 1000 & 0.57 & 0.57 & 0.57 \\
        \hline
    \end{tabular}
    \caption{Metrics}
    \label{tab:metrics}
\end{table}

\section{Part 5 — Final Evaluation and Analysis}
\subsection{Baseline Evaluation}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/eval_baseline.png}
    \caption{Baseline Evaluation}
    \label{fig:eval_baseline}
\end{figure}
The baseline accuracy is 60.88\% as shown in the figure \ref{fig:eval_baseline}.


\subsection{Trained Model Evaluation}

\end{document}